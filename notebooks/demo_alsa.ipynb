{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-LSA Demonstration Notebook\n",
    "\n",
    "**Adaptive Latent Semantic Analysis for Binary Text Classification**\n",
    "\n",
    "Author: Isaac Touza  \n",
    "Institution: Université de Maroua, Cameroun  \n",
    "Date: January 2026\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates the complete A-LSA workflow:\n",
    "1. Data loading and preprocessing\n",
    "2. Model training\n",
    "3. Evaluation and comparison with baselines\n",
    "4. Visualization and interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.alsa import AdaptiveLSA\n",
    "from src.baselines import get_baseline_models\n",
    "from src.evaluation import evaluate_model, cross_validate_model, get_confusion_matrix\n",
    "from src.visualization import (\n",
    "    plot_tsne_visualization,\n",
    "    plot_characteristic_terms,\n",
    "    plot_performance_comparison\n",
    ")\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "We'll use the 20 Newsgroups dataset (binary: comp.graphics vs rec.sport.hockey) for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 20 Newsgroups dataset\n",
    "categories = ('comp.graphics', 'rec.sport.hockey')\n",
    "\n",
    "print(\"Loading 20 Newsgroups dataset...\")\n",
    "data = fetch_20newsgroups(\n",
    "    subset='all',\n",
    "    categories=categories,\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(f\"✓ Loaded {len(X)} documents\")\n",
    "print(f\"  - {categories[0]}: {np.sum(y == 0)} documents\")\n",
    "print(f\"  - {categories[1]}: {np.sum(y == 1)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example documents\n",
    "print(\"Example from comp.graphics:\")\n",
    "print(\"-\" * 80)\n",
    "print(X[y == 0][0][:300] + \"...\\n\")\n",
    "\n",
    "print(\"Example from rec.sport.hockey:\")\n",
    "print(\"-\" * 80)\n",
    "print(X[y == 1][0][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} documents\")\n",
    "print(f\"Test set: {len(X_test)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train A-LSA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize A-LSA\n",
    "alsa = AdaptiveLSA(\n",
    "    n_components=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training A-LSA model...\")\n",
    "alsa.fit(X_train, y_train)\n",
    "print(\"✓ Training complete\")\n",
    "\n",
    "# Show model parameters\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  - Latent dimension k: {alsa.n_components}\")\n",
    "print(f\"  - Vocabulary size: {alsa.preprocessor_.get_vocabulary_size()}\")\n",
    "print(f\"  - Decision threshold θ: {alsa.theta_:.4f}\")\n",
    "print(f\"  - N+ (positive class): {alsa.n_pos_}\")\n",
    "print(f\"  - N- (negative class): {alsa.n_neg_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate A-LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "metrics = evaluate_model(alsa, X_test, y_test, \"A-LSA\")\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(\"-\" * 40)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric:25s}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm, cm_df = get_confusion_matrix(\n",
    "    alsa, X_test, y_test,\n",
    "    class_names=['comp.graphics', 'rec.sport.hockey']\n",
    ")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare with Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline models\n",
    "baselines = get_baseline_models(n_components=100, random_state=42)\n",
    "\n",
    "# Evaluate all models\n",
    "results = []\n",
    "\n",
    "for model_name, model in [('A-LSA', alsa)] + list(baselines.items()):\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    if model_name != 'A-LSA':\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    metrics = evaluate_model(model, X_test, y_test, model_name)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'F1 (macro)': metrics['F1-score (macro)'],\n",
    "        'Accuracy': metrics['Accuracy'],\n",
    "        'Precision': metrics['Precision (macro)'],\n",
    "        'Recall': metrics['Recall (macro)']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('F1 (macro)', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.2\n",
    "\n",
    "ax.bar(x - 1.5*width, results_df['F1 (macro)'], width, label='F1 (macro)', alpha=0.8)\n",
    "ax.bar(x - 0.5*width, results_df['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "ax.bar(x + 0.5*width, results_df['Precision'], width, label='Precision', alpha=0.8)\n",
    "ax.bar(x + 1.5*width, results_df['Recall'], width, label='Recall', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Model', fontweight='bold')\n",
    "ax.set_ylabel('Score', fontweight='bold')\n",
    "ax.set_title('Model Performance Comparison', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim([0.80, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Characteristic Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get characteristic terms\n",
    "char_terms = alsa.get_characteristic_terms(n_terms=15)\n",
    "\n",
    "print(\"Top 15 Characteristic Terms per Class:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n{categories[1]} (Positive Class):\")\n",
    "print(\"-\" * 30)\n",
    "for i, (term, weight) in enumerate(char_terms['positive'][:15], 1):\n",
    "    print(f\"{i:2d}. {term:20s} (weight: {abs(weight):.4f})\")\n",
    "\n",
    "print(f\"\\n{categories[0]} (Negative Class):\")\n",
    "print(\"-\" * 30)\n",
    "for i, (term, weight) in enumerate(char_terms['negative'][:15], 1):\n",
    "    print(f\"{i:2d}. {term:20s} (weight: {abs(weight):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize characteristic terms\n",
    "plot_characteristic_terms(\n",
    "    terms_pos=char_terms['positive'],\n",
    "    terms_neg=char_terms['negative'],\n",
    "    class_names=['comp.graphics', 'rec.sport.hockey'],\n",
    "    n_terms=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Latent Spaces with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latent projections for test set\n",
    "print(\"Computing latent projections...\")\n",
    "z_pos, z_neg = alsa.get_latent_projections(X_test)\n",
    "\n",
    "print(f\"Positive space projections: {z_pos.shape}\")\n",
    "print(f\"Negative space projections: {z_neg.shape}\")\n",
    "\n",
    "# Visualize with t-SNE\n",
    "plot_tsne_visualization(\n",
    "    z_pos=z_pos,\n",
    "    z_neg=z_neg,\n",
    "    y_true=y_test,\n",
    "    class_names=['comp.graphics', 'rec.sport.hockey'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyze Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute differential semantic distances\n",
    "distances = alsa.decision_function(X_test)\n",
    "\n",
    "# Visualize distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot histograms\n",
    "ax.hist(distances[y_test == 0], bins=50, alpha=0.6, label='comp.graphics', color='red')\n",
    "ax.hist(distances[y_test == 1], bins=50, alpha=0.6, label='rec.sport.hockey', color='blue')\n",
    "\n",
    "# Plot threshold\n",
    "ax.axvline(alsa.theta_, color='green', linestyle='--', linewidth=2, \n",
    "           label=f'Threshold θ={alsa.theta_:.4f}')\n",
    "\n",
    "ax.set_xlabel('Differential Semantic Distance (Δ_sem)', fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontweight='bold')\n",
    "ax.set_title('Distribution of Differential Semantic Distances', fontweight='bold', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDistance Statistics:\")\n",
    "print(f\"  Mean (comp.graphics): {np.mean(distances[y_test == 0]):.4f}\")\n",
    "print(f\"  Mean (rec.sport.hockey): {np.mean(distances[y_test == 1]):.4f}\")\n",
    "print(f\"  Separation: {abs(np.mean(distances[y_test == 0]) - np.mean(distances[y_test == 1])):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "cv_results = cross_validate_model(\n",
    "    alsa,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Prediction Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample documents\n",
    "test_samples = [\n",
    "    \"I love playing hockey and watching NHL games with my friends.\",\n",
    "    \"Need help with 3D graphics rendering and OpenGL programming.\",\n",
    "    \"The Maple Leafs won the game last night in overtime!\",\n",
    "    \"How do I create realistic shadows in my ray tracing algorithm?\"\n",
    "]\n",
    "\n",
    "print(\"Prediction Examples:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, text in enumerate(test_samples, 1):\n",
    "    pred = alsa.predict([text])[0]\n",
    "    proba = alsa.predict_proba([text])[0]\n",
    "    distance = alsa.decision_function([text])[0]\n",
    "    \n",
    "    print(f\"\\n{i}. {text}\")\n",
    "    print(f\"   Prediction: {categories[pred]}\")\n",
    "    print(f\"   Probabilities: {categories[0]}={proba[0]:.4f}, {categories[1]}={proba[1]:.4f}\")\n",
    "    print(f\"   Distance: {distance:.4f} (threshold: {alsa.theta_:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete A-LSA workflow:\n",
    "\n",
    "1. ✓ Loaded and explored 20 Newsgroups dataset\n",
    "2. ✓ Trained A-LSA model with dual latent spaces\n",
    "3. ✓ Evaluated performance against baselines\n",
    "4. ✓ Analyzed characteristic terms for each class\n",
    "5. ✓ Visualized latent spaces with t-SNE\n",
    "6. ✓ Examined decision boundaries\n",
    "7. ✓ Performed cross-validation\n",
    "8. ✓ Tested predictions on new documents\n",
    "\n",
    "**Key Findings:**\n",
    "- A-LSA achieves competitive performance with baselines\n",
    "- Class-specific latent spaces capture semantic differences\n",
    "- Differential semantic distance provides interpretable classification\n",
    "- Threshold θ effectively handles class imbalance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
